# Income Analysis Workflow Refactor

## Date: January 2025

## Problem Identified

The original workflow had a **subtle but critical architecture issue**:

### Original (Incorrect) Workflow:
```
1. income_scenario_classifier.py
   â””â”€> Used simple keyword search ('W2', 'PAYSTUB', etc.)
   â””â”€> May include/exclude wrong documents
   â””â”€> Classified scenario based on potentially incorrect document set

2. income_analysis_agent.py
   â””â”€> Properly filtered documents using LLM + Freddie Mac guidelines
   â””â”€> But scenario was already classified with wrong context!
```

### The Issue:
- **Scenario classifier** used basic keyword matching â†’ might classify based on wrong documents
- **Income analyzer** ran proper filtering â†’ but too late, scenario already set
- This could lead to:
  - Wrong scenario classification (e.g., calling it "complex" when it's really "simple")
  - Incorrect decision tree path in income calculation
  - Inconsistent results across runs

## Solution Implemented

### Correct Workflow (After Refactoring):
```
1. income_scenario_classifier.py
   â”œâ”€> Checks if documents already have income_verification_relevant flags
   â”œâ”€> If NOT: Imports filter_income_documents_by_guidelines() from income_analysis_agent
   â”œâ”€> Runs LLM-based filtering using Freddie Mac guidelines
   â”œâ”€> Caches results to semantic JSON files (income_verification_relevant flag)
   â”œâ”€> Then uses ONLY the filtered documents for scenario classification
   â””â”€> Outputs: income_scenario.json

2. income_analysis_agent.py
   â”œâ”€> Loads documents (flags already exist from step 1)
   â”œâ”€> Uses FAST PATH (cached flags, no LLM needed)
   â”œâ”€> Loads scenario.json
   â”œâ”€> Calculates income using decision tree + scenario context
   â””â”€> Outputs: income_analysis_runX.json
```

## Changes Made

### File: `agents/income_scenario_classifier.py`

**Lines 189-238 (Refactored):**

```python
# Check if documents have been filtered yet
has_cached_flags = False
for doc_file in loan_docs_dir.glob("*.json"):
    try:
        with open(doc_file, 'r', encoding='utf-8') as f:
            doc = json.load(f)
            if 'income_verification_relevant' in doc:
                has_cached_flags = True
                break
    except:
        continue

# If no cached flags exist, run document filtering FIRST
if not has_cached_flags:
    print(f"\n>> No income_verification_relevant flags found - filtering documents first...")
    print(f">> Importing document filtering from income_analysis_agent...")
    
    # Import the filtering function
    import sys
    sys.path.insert(0, str(Path(__file__).parent))
    from income_analysis_agent import filter_income_documents_by_guidelines
    
    # Run the filtering to populate the flags
    try:
        await filter_income_documents_by_guidelines(loan_id, refilter=False)
        print(f">> âœ“ Document filtering complete - flags cached to semantic JSON files")
    except Exception as e:
        print(f">> âš ï¸  Warning: Document filtering failed: {e}")
        print(f">> Falling back to keyword search...")

# Now load income documents using the cached flags
income_docs = []

for doc_file in loan_docs_dir.glob("*.json"):
    try:
        with open(doc_file, 'r', encoding='utf-8') as f:
            doc = json.load(f)
            
            # Check if this document has been classified
            if 'income_verification_relevant' in doc:
                if doc['income_verification_relevant'].get('is_relevant', False):
                    income_docs.append(doc)
            else:
                # Fallback to keyword search if filtering failed
                doc_type = doc.get('metadata', {}).get('DocPredictionType', '')
                spring_type = doc.get('metadata', {}).get('SpringDocType', '')
                if any(keyword in doc_type.upper() or keyword in spring_type.upper() 
                       for keyword in ['W2', 'W-2', 'PAYSTUB', 'PAY STUB', 'VOE', 'VERIFICATION OF EMPLOYMENT', '1099']):
                    income_docs.append(doc)
    except:
        continue
```

## Benefits

1. **Correct Document Set**: Scenario classification now uses the SAME filtered document set as income analysis
2. **Caching Efficiency**: Document filtering only runs once per loan, results cached for all future runs
3. **Consistency**: Both scenario and income calculation work from the same foundation
4. **Guideline Compliance**: LLM applies Freddie Mac guidelines to identify PRIMARY SOURCE documents
5. **Smart Fallback**: If filtering fails, falls back to keyword search (maintains compatibility)

## Document Flagging System

Each semantic JSON file now contains:

```json
{
  "metadata": { ... },
  "semantic_content": { ... },
  "income_verification_relevant": {
    "is_relevant": true,
    "reason": "Primary source W-2 showing wage income from employer",
    "classified_date": "1234567890.123"
  }
}
```

### What Gets Flagged as Relevant:

**INCLUDED** (is_relevant: true):
- âœ… Paystubs (recent, from employer)
- âœ… W-2 forms (IRS tax documents)
- âœ… 1099 forms (independent contractor income)
- âœ… Tax returns (when needed for self-employment)
- âœ… Pension/retirement benefit statements
- âœ… SSA benefit letters
- âœ… Bank statements (when showing deposits for income verification)

**EXCLUDED** (is_relevant: false):
- âŒ Underwriter worksheets/notes
- âŒ Loan officer internal documents
- âŒ VOE responses (verify employment, not primary source for income amount)
- âŒ Income analysis summaries
- âŒ Corporate structure explanations
- âŒ Employment verification letters (unless showing income)

## Testing Recommendations

1. **Test Fresh Loans**: Run classifier on loans without cached flags to verify filtering works
2. **Verify Consistency**: Re-run tested loans to see if scenario classifications change
3. **Check Variance**: Test if this improves consistency in income calculations (reduces variance)
4. **Compare Before/After**: Compare scenarios classified before vs after refactoring

## Next Steps

1. âœ… **Refactoring Complete**: Document filtering now runs before scenario classification
2. â³ **Test Workflow**: Test on fresh loans to verify end-to-end workflow
3. â³ **Measure Impact**: Compare variance before/after refactoring
4. â³ **Update Documentation**: Update README with new workflow

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LOAN DOCUMENTS                           â”‚
â”‚  loan_docs/{loan_id}/semantic_json/*.json                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         STEP 1: DOCUMENT FILTERING                          â”‚
â”‚  income_scenario_classifier.py                              â”‚
â”‚  â”œâ”€> Check for cached flags                                 â”‚
â”‚  â”œâ”€> If none: Import filter_income_documents_by_guidelines()â”‚
â”‚  â”œâ”€> LLM + Freddie Mac Guidelines                           â”‚
â”‚  â””â”€> Cache income_verification_relevant flags               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         STEP 2: SCENARIO CLASSIFICATION                     â”‚
â”‚  income_scenario_classifier.py                              â”‚
â”‚  â”œâ”€> Load ONLY flagged documents (is_relevant: true)        â”‚
â”‚  â”œâ”€> Classify income scenario                               â”‚
â”‚  â””â”€> Output: income_scenario.json                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         STEP 3: INCOME CALCULATION                          â”‚
â”‚  income_analysis_agent.py                                   â”‚
â”‚  â”œâ”€> Load flagged documents (FAST PATH - cached)            â”‚
â”‚  â”œâ”€> Load income_scenario.json                              â”‚
â”‚  â”œâ”€> Apply decision tree with scenario context              â”‚
â”‚  â””â”€> Output: income_analysis_runX.json                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Key Insight

**The scenario classification is only as good as the documents it's based on.**

By ensuring the scenario classifier uses the SAME rigorously-filtered document set as the income analyzer, we create a consistent foundation for the entire income analysis workflow.

This refactoring moves us from:
- "Classify scenario based on whatever keyword search finds, then filter properly later"

To:
- "Filter properly ONCE, then both scenario and income calculation use the correct documents"

Much better architecture! ðŸŽ¯
